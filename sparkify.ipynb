{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTGCOdRybCo9"
   },
   "source": [
    "# Sparkify Churn Prediction\n",
    "\n",
    "This notebook provides you the practical machine learning implementation to predict churn using a fictional digital music streaming service.\n",
    "\n",
    "The dataset is from a fictional digital music streaming service called Sparkify. It contains several potentially interesting fields derived from website interaction logs.\n",
    "\n",
    "We are using Spark since the dataset is 12GB and we need the power of distributed machine learning technologies to help us with the heavy lifting.\n",
    "\n",
    "In our case, Churn is defined as page == \"Cancellation Confirmation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "1a95edd2af4f42c2b0ca1e5f66032f89",
      ""
     ]
    },
    "id": "djlXXH1qbCo_",
    "outputId": "b9e24eb0-e3d2-4e9a-9fd4-1ae0788c80b7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efb7a891bda4d95b17080b79d53d925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>16</td><td>application_1604373716901_0017</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-19-65.us-west-2.compute.internal:20888/proxy/application_1604373716901_0017/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-17-93.us-west-2.compute.internal:8042/node/containerlogs/container_1604373716901_0017_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                    Version  \n",
      "-------------------------- ---------\n",
      "beautifulsoup4             4.9.1    \n",
      "boto                       2.49.0   \n",
      "click                      7.1.2    \n",
      "jmespath                   0.10.0   \n",
      "joblib                     0.16.0   \n",
      "lxml                       4.5.2    \n",
      "mysqlclient                1.4.2    \n",
      "nltk                       3.5      \n",
      "nose                       1.3.4    \n",
      "numpy                      1.16.5   \n",
      "pip                        9.0.1    \n",
      "py-dateutil                2.2      \n",
      "python37-sagemaker-pyspark 1.4.0    \n",
      "pytz                       2020.1   \n",
      "PyYAML                     5.3.1    \n",
      "regex                      2020.7.14\n",
      "setuptools                 28.8.0   \n",
      "six                        1.13.0   \n",
      "soupsieve                  1.9.5    \n",
      "tqdm                       4.48.2   \n",
      "wheel                      0.29.0   \n",
      "windmill                   1.6"
     ]
    }
   ],
   "source": [
    "sc.list_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "1ea6e398d1974733905781708d11a8fe",
      ""
     ]
    },
    "id": "Q3UN9YPzbCpG",
    "outputId": "05bde77f-c75f-4acd-dbaf-6a9932633f4c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546a7151419e4cf5b5f1208407b280d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/bf/4c/cb7da76f3a5e077e545f9cf8575b8f488a4e8ad60490838f89c5cdd5bb57/pandas-1.1.4-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib64/python3.7/site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-1.1.4 python-dateutil-2.8.1"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "edd1e7da16b4483caec6da827a2f4ea3",
      ""
     ]
    },
    "id": "hISWlA2gbCpK",
    "outputId": "0fa43169-6ea4-4fae-d204-3f36d80c1ad6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df7b39eb73c418e83f5b4fd4c6e342f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pyspark libraries\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, col, date_trunc, desc, asc, to_date\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, IndexToString, StringIndexer, Normalizer, StandardScaler, VectorAssembler, VectorSlicer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# import python libraries\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fb095d497d0c4a9aa8cef11695eca2d9",
      ""
     ]
    },
    "id": "SljTch7bbCpO",
    "outputId": "bac7fa41-f992-4fdf-bc8c-986361419092"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d5ed24b18c4acfba3b0ad7b9a4ed1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1q6hMwrVbCpS"
   },
   "source": [
    "# Load and Clean Dataset\n",
    "\n",
    "We will load two datasets. First the full 12GB dataset and second a mini dataset for some early data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a052eaa04026440fad92ee86c7c34d2f",
      ""
     ]
    },
    "id": "SjTbnNMSbCpS",
    "outputId": "c3adb16c-6dee-472c-8516-27abdd3739cb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65095320d557493d9de601359a1ca62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Popol Vuh', auth='Logged In', firstName='Shlok', gender='M', itemInSession=278, lastName='Johnson', length=524.32934, level='paid', location='Dallas-Fort Worth-Arlington, TX', method='PUT', page='NextSong', registration=1533734541000, sessionId=22683, song='Ich mache einen Spiegel - Dream Part 4', status=200, ts=1538352001000, userAgent='\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId='1749042')"
     ]
    }
   ],
   "source": [
    "# Read in full sparkify dataset\n",
    "event_data = \"s3n://udacity-dsnd/sparkify/sparkify_event_data.json\"\n",
    "df = spark.read.json(event_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "285a0dd97221461d95ea5d8ba7bdcceb",
      ""
     ]
    },
    "id": "suRFsWxMbCpX",
    "outputId": "fab43c2a-862e-4267-93b6-159c41089942"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285a0dd97221461d95ea5d8ba7bdcceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Martha Tilston', auth='Logged In', firstName='Colin', gender='M', itemInSession=50, lastName='Freeman', length=277.89016, level='paid', location='Bakersfield, CA', method='PUT', page='NextSong', registration=1538173362000, sessionId=29, song='Rockpools', status=200, ts=1538352117000, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0', userId='30')"
     ]
    }
   ],
   "source": [
    "# Read in small sparkify dataset\n",
    "mini_event_data = \"s3n://udacity-dsnd/sparkify/mini_sparkify_event_data.json\"\n",
    "df_mini = spark.read.json(mini_event_data)\n",
    "df_mini.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai72X-W6bCpa"
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "We will perform EDA on the small subset of the data\n",
    "\n",
    "### Define Churn\n",
    "\n",
    "Churn is defined as page == `Cancellation Confirmation` events. The implementation of this will happen later in our Feature Engineering section\n",
    "\n",
    "\n",
    "### Explore Data\n",
    "See exploration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "5ee102ea71e84a92b0ec8f78e24e788b",
      ""
     ]
    },
    "id": "WRLkzsaSbCpa",
    "outputId": "fd6a3000-31ea-4055-8a23-b12df1e88872"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee102ea71e84a92b0ec8f78e24e788b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   artist       auth  ...                                          userAgent  userId\n",
      "0    None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...      18\n",
      "1    None  Cancelled  ...  \"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like...      32\n",
      "2    None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     125\n",
      "3    None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...     105\n",
      "4    None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:24.0) G...      17\n",
      "5    None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     143\n",
      "6    None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.2; WOW64; rv:31.0) G...     101\n",
      "7    None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebK...     129\n",
      "8    None  Cancelled  ...  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:31....     121\n",
      "9    None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...      51\n",
      "10   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...      87\n",
      "11   None  Cancelled  ...  Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:31.0)...     122\n",
      "12   None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.3; WOW64; rv:31.0) G...      12\n",
      "13   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebK...      58\n",
      "14   None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...      73\n",
      "15   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       3\n",
      "16   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     106\n",
      "17   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     103\n",
      "18   None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7....      28\n",
      "19   None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:32.0) G...      54\n",
      "20   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...      29\n",
      "21   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...      70\n",
      "22   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2...      53\n",
      "23   None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  100011\n",
      "24   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8...  100001\n",
      "25   None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.1; rv:31.0) Gecko/20...  100024\n",
      "26   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebK...  100006\n",
      "27   None  Cancelled  ...  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:31....  100019\n",
      "28   None  Cancelled  ...  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) G...  100003\n",
      "29   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  100023\n",
      "30   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  100005\n",
      "31   None  Cancelled  ...  \"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like...  100017\n",
      "32   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  100025\n",
      "33   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  100009\n",
      "34   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  100012\n",
      "35   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537....  100013\n",
      "36   None  Cancelled  ...  Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...  100022\n",
      "37   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  100014\n",
      "38   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  100015\n",
      "39   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  100021\n",
      "40   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebK...  100007\n",
      "41   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...  200001\n",
      "42   None  Cancelled  ...  Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:31....  200024\n",
      "43   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  200011\n",
      "44   None  Cancelled  ...  Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; r...  200021\n",
      "45   None  Cancelled  ...  \"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like...  200018\n",
      "46   None  Cancelled  ...  \"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like...  200015\n",
      "47   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  200017\n",
      "48   None  Cancelled  ...  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  200016\n",
      "49   None  Cancelled  ...  Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...  200020\n",
      "50   None  Cancelled  ...  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...  300007\n",
      "51   None  Cancelled  ...  \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537....  300001\n",
      "\n",
      "[52 rows x 18 columns]"
     ]
    }
   ],
   "source": [
    "# find all the members who have churned\n",
    "df_mini.filter(\"page = 'Cancellation Confirmation'\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fdddd5001fd4404baabfe07ec47dbeb4",
      ""
     ]
    },
    "id": "fixHGJJibCpd",
    "outputId": "a36754ed-fa3d-4dfa-c688-389062788e9b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdddd5001fd4404baabfe07ec47dbeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userId firstname  ... level                                               song\n",
      "0       18    Adriel  ...  paid                                               None\n",
      "1       18    Adriel  ...  paid                        A Beggar On A Beach Of Gold\n",
      "2       18    Adriel  ...  paid         ...slowdance On The Inside (Album Version)\n",
      "3       18    Adriel  ...  paid                                      St. Apollonia\n",
      "4       18    Adriel  ...  paid                                     Drunk Stripper\n",
      "..     ...       ...  ...   ...                                                ...\n",
      "508     18    Adriel  ...  paid  Nasty Girl (Featuring Diddy_ Nelly_ Jagged Edg...\n",
      "509     18    Adriel  ...  paid                                            Someday\n",
      "510     18    Adriel  ...  paid                                               None\n",
      "511     18    Adriel  ...  paid                                               None\n",
      "512     18    Adriel  ...  paid                                               None\n",
      "\n",
      "[513 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "# look at the user journey of a member who has cancelled\n",
    "df_mini.select([\"userId\", \"firstname\", \"page\", \"level\", \"song\"]).where(df_mini.userId == \"18\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "148e2d373c974c5c9262d41fc7a0be46",
      ""
     ]
    },
    "id": "dNLaVEE4bCpg",
    "outputId": "b6c49f7e-2a80-4c0b-89f1-14f72f22dfe9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148e2d373c974c5c9262d41fc7a0be46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "# check out full schema \n",
    "df_mini.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "71f4183b3b38453fbb6b5b8a68c11846",
      ""
     ]
    },
    "id": "6wl4QzZibCpi",
    "outputId": "31c4b6ef-a0fb-433a-ef19-d28f59cabe83"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f4183b3b38453fbb6b5b8a68c11846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary  ...              userId\n",
      "0   count  ...              286500\n",
      "1    mean  ...   59682.02278593872\n",
      "2  stddev  ...  109091.94999910519\n",
      "3     min  ...                    \n",
      "4     max  ...                  99\n",
      "\n",
      "[5 rows x 19 columns]"
     ]
    }
   ],
   "source": [
    "# describe each column\n",
    "df_mini.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "0f617cfde6a5484586eec2bd3b21121c",
      ""
     ]
    },
    "id": "nMIfKvP_bCpl",
    "outputId": "151c2e81-2e6d-4bc4-e830-a40701f2d258"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f617cfde6a5484586eec2bd3b21121c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|                  ts|\n",
      "+-------+--------------------+\n",
      "|  count|              286500|\n",
      "|   mean|1.540956889810471...|\n",
      "| stddev|  1.50754396081869E9|\n",
      "|    min|       1538352117000|\n",
      "|    max|       1543799476000|\n",
      "+-------+--------------------+"
     ]
    }
   ],
   "source": [
    "# describe 'ts'\n",
    "df_mini.describe(\"ts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "b32a0ce5d0824c8eb4e69274a429f971",
      ""
     ]
    },
    "id": "V25gA1fJbCpn",
    "outputId": "efcbe8b8-de81-4c9f-b095-9e983ea0fb4b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32a0ce5d0824c8eb4e69274a429f971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         page   count\n",
      "0                    NextSong  228108\n",
      "1                        Home   14457\n",
      "2                   Thumbs Up   12551\n",
      "3             Add to Playlist    6526\n",
      "4                  Add Friend    4277\n",
      "5                 Roll Advert    3933\n",
      "6                       Login    3241\n",
      "7                      Logout    3226\n",
      "8                 Thumbs Down    2546\n",
      "9                   Downgrade    2055\n",
      "10                       Help    1726\n",
      "11                   Settings    1514\n",
      "12                      About     924\n",
      "13                    Upgrade     499\n",
      "14              Save Settings     310\n",
      "15                      Error     258\n",
      "16             Submit Upgrade     159\n",
      "17           Submit Downgrade      63\n",
      "18                     Cancel      52\n",
      "19  Cancellation Confirmation      52\n",
      "20                   Register      18\n",
      "21        Submit Registration       5"
     ]
    }
   ],
   "source": [
    "# look at a orderd count for all events in the page field\n",
    "df_mini.select('page').groupBy('page').count().orderBy(desc('count')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "3185c686f998463a970a9e10426e37a1",
      ""
     ]
    },
    "id": "TucunwvhbCpp",
    "outputId": "e65c4c17-df05-41a0-d9c2-d503afb0da70"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3185c686f998463a970a9e10426e37a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|              Artist|Artistcount|\n",
      "+--------------------+-----------+\n",
      "|       Kings Of Leon|       1841|\n",
      "|            Coldplay|       1813|\n",
      "|Florence + The Ma...|       1236|\n",
      "|       Dwight Yoakam|       1135|\n",
      "|            BjÃÂ¶rk|       1133|\n",
      "|      The Black Keys|       1125|\n",
      "|                Muse|       1090|\n",
      "|       Justin Bieber|       1044|\n",
      "|        Jack Johnson|       1007|\n",
      "|              Eminem|        953|\n",
      "+--------------------+-----------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "# what were the top 10 artists played\n",
    "df_mini.filter(df_mini.page == 'NextSong') \\\n",
    "    .select('Artist') \\\n",
    "    .groupBy('Artist') \\\n",
    "    .agg({'Artist':'count'}) \\\n",
    "    .withColumnRenamed('count(Artist)', 'Artistcount') \\\n",
    "    .sort(desc('Artistcount')) \\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4o0m3AwsbCps"
   },
   "source": [
    "# Feature Engineering\n",
    "Now that we have familiarized ourselves with the data, lets build out the features we find promising to train our model on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "7eee11c22889436bbe03a68b0137b0c5",
      ""
     ]
    },
    "id": "f3FM-I77bCpt",
    "outputId": "4a364108-1dd7-4d09-80b4-ba05e56b65ef"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4d309a54da4f1ea826649ecd6d342d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    '''\n",
    "    Function to go through all the Feature Engineering steps\n",
    "    \n",
    "    INPUT: df - as DataFrame\n",
    "    OUTPUT: df - prepped with all the features\n",
    "    \n",
    "    '''\n",
    "    # Create OneHotEncoder df\n",
    "    # use StringIndexer to convert categorical column to indexed\n",
    "    indexer = StringIndexer(inputCol=\"page\", outputCol=\"pageIndex\")\n",
    "    indexed = indexer.fit(df).transform(df)\n",
    "\n",
    "    # use OneHotEncoder to convert indexed to SparseVector\n",
    "    encoder = OneHotEncoder(dropLast=False,\n",
    "                            inputCol=\"pageIndex\",\n",
    "                            outputCol=\"page_categoryVec\")\n",
    "\n",
    "    encoded = encoder.transform(indexed)\n",
    "    \n",
    "    # make a list of all the columns to name the columns of the Matrix DataFrame\n",
    "    columns_for_vector = pd.Series(['NextSong','Home','Thumbs Up','Add to Playlist',\n",
    "                          'Add Friend','Roll Advert','Login','Logout','Thumbs Down',\n",
    "                          'Downgrade','Help','Settings','About','Upgrade','Save Settings',\n",
    "                          'Error', 'Submit Upgrade', 'Submit Downgrade','Cancel',\n",
    "                          'Cancellation Confirmation','Register','Submit Registration'])\n",
    "\n",
    "    existing_columns = pd.Series(encoded.columns)\n",
    "\n",
    "    # concat full columns list\n",
    "    columns = pd.concat([existing_columns,columns_for_vector]).tolist()\n",
    "    \n",
    "    # create matrix DataFrame from SparseVector\n",
    "    def extract(row):\n",
    "        return (row.artist,row.auth,row.firstName,row.gender,\n",
    "                row.itemInSession,row.lastName,row.length,row.level,\n",
    "                row.location,row.method,row.page,row.registration,\n",
    "                row.sessionId,row.song,row.status,row.ts,row.userAgent,\n",
    "                row.userId,row.pageIndex,\n",
    "                row.page_categoryVec,) + tuple(row.page_categoryVec.toArray().tolist())\n",
    "\n",
    "    vector_matrix_df = encoded.rdd.map(extract).toDF(columns)\n",
    "    \n",
    "    # Date manipulations\n",
    "    # Create a function that returns string from a timestamp \n",
    "    def format_timestamp(ts):\n",
    "        return dt.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create a date formating UDF\n",
    "    format_timestamp_udf = udf(lambda x: format_timestamp(x/1000.0))\n",
    "\n",
    "    # new date column outputs\n",
    "    vector_matrix_df = vector_matrix_df.withColumn(\"str_date\", format_timestamp_udf(vector_matrix_df.ts))\n",
    "    vector_matrix_df = vector_matrix_df.withColumn(\"date\", to_date(vector_matrix_df.str_date))\n",
    "    vector_matrix_df=(vector_matrix_df.withColumn('dayssinceJan11900',F.datediff(vector_matrix_df.date,F.lit(dt.datetime(1900, 1, 1)))))\n",
    "\n",
    "    # keep necessary columns\n",
    "    dimensions_to_keep = pd.Series(['userId','date','dayssinceJan11900'])\n",
    "    numeric_columns_to_keep = columns_for_vector\n",
    "\n",
    "    # create daily_df\n",
    "    columns_for_daily_df = pd.concat([dimensions_to_keep,numeric_columns_to_keep]).tolist()\n",
    "    daily_df_staging = vector_matrix_df.select(columns_for_daily_df)\n",
    "    daily_df = daily_df_staging.groupBy('userId','date','dayssinceJan11900').sum()\n",
    "\n",
    "    # drop and rename \n",
    "    daily_df = daily_df.drop(\"sum(dayssinceJan11900)\") # not needed\n",
    "    daily_df = daily_df.drop(\"sum(Cancel)\") # drop this, because it's essentially the same as Churn\n",
    "    daily_df = daily_df.withColumnRenamed(\"sum(Cancellation Confirmation)\",\"sum(Churn)\") # redefine churn for daily_df\n",
    "    \n",
    "    # create numeric columns list\n",
    "    columns_for_counter = daily_df.columns\n",
    "    del columns_for_counter[0:3]\n",
    "    del columns_for_counter[columns_for_counter.index('sum(Churn)')]\n",
    "    \n",
    "    # 7d Averages for all numeric matrix \n",
    "    # initiate Window value\n",
    "    windowval = Window \\\n",
    "        .partitionBy(\"userId\") \\\n",
    "        .orderBy(asc(\"dayssinceJan11900\")) \\\n",
    "        .rangeBetween(-7, 0)\n",
    "\n",
    "    # loop through all columns\n",
    "    for x in columns_for_counter:\n",
    "        daily_df = daily_df \\\n",
    "            .withColumn(\"{}_7d_avg\".format(x), F.avg(x).over(windowval))\n",
    "        \n",
    "    # 30d Averages for all numeric matrix \n",
    "    # initiate Window value\n",
    "    windowval = Window \\\n",
    "        .partitionBy(\"userId\") \\\n",
    "        .orderBy(asc(\"dayssinceJan11900\")) \\\n",
    "        .rangeBetween(-30, 0)\n",
    "\n",
    "    # loop through all columns\n",
    "    for x in columns_for_counter:\n",
    "        daily_df = daily_df \\\n",
    "            .withColumn(\"{}_30d_avg\".format(x), F.avg(x).over(windowval))\n",
    "    \n",
    "    # create numeric columns list subset for daily\n",
    "    columns_for_daily = daily_df.columns\n",
    "    start_index = columns_for_daily.index('dayssinceJan11900')\n",
    "    del columns_for_daily[0:start_index+1]\n",
    "    end_index = columns_for_daily.index('sum(Submit Registration)')\n",
    "    del columns_for_daily[end_index+1:]\n",
    "    del columns_for_daily[columns_for_daily.index('sum(Churn)')]\n",
    "    \n",
    "    # create numeric columns list subset for 7d avg\n",
    "    columns_for_7d_avg = daily_df.columns\n",
    "    start_index = columns_for_7d_avg.index('sum(Submit Registration)')\n",
    "    del columns_for_7d_avg[0:start_index+1]\n",
    "    end_index = columns_for_7d_avg.index('sum(Submit Registration)_7d_avg')\n",
    "    del columns_for_7d_avg[end_index+1:]\n",
    "    \n",
    "    # create numeric columns list subset for 30d avg\n",
    "    columns_for_30d_avg = daily_df.columns\n",
    "    start_index = columns_for_30d_avg.index('sum(Submit Registration)_7d_avg')\n",
    "    del columns_for_30d_avg[0:start_index+1]\n",
    "    \n",
    "    # Loop through pairs to create variance to the mean metric\n",
    "    # Create variance metric\n",
    "    for i,n in zip(columns_for_daily,columns_for_7d_avg):\n",
    "        daily_df = daily_df \\\n",
    "            .withColumn('variance_daily_to_7d_avg_{}'.format(i), \\\n",
    "                        (daily_df[i] - daily_df[n]) \\\n",
    "                        / daily_df[n])\n",
    "        \n",
    "    # Create variance metric\n",
    "    for i,n in zip(columns_for_daily,columns_for_30d_avg):\n",
    "        daily_df = daily_df \\\n",
    "            .withColumn('variance_daily_to_30d_avg_{}'.format(i), \\\n",
    "                        (daily_df[i] - daily_df[n]) \\\n",
    "                        / daily_df[n])\n",
    "        \n",
    "    # Create variance metric\n",
    "    for i,n in zip(columns_for_7d_avg,columns_for_30d_avg):\n",
    "        daily_df = daily_df \\\n",
    "            .withColumn('variance_7d_avg_to_30d_avg_{}'.format(i), \\\n",
    "                        (daily_df[i] - daily_df[n]) \\\n",
    "                        / daily_df[n])\n",
    "        \n",
    "    # Getting days on platform as a tenure metric\n",
    "    # Adjust window\n",
    "    windowval = Window \\\n",
    "        .partitionBy(\"userId\") \\\n",
    "        .orderBy(asc(\"dayssinceJan11900\")) \\\n",
    "        .rangeBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "    # Create min date\n",
    "    daily_df = daily_df \\\n",
    "        .withColumn(\"min_date\", F.min(\"dayssinceJan11900\").over(windowval))\n",
    "\n",
    "    # Create Tenure metric\n",
    "    daily_df = daily_df \\\n",
    "        .withColumn('tenure', (daily_df['dayssinceJan11900'] - daily_df['min_date']) )\n",
    "    \n",
    "    \n",
    "    # fill NULL values with 0\n",
    "    daily_df = daily_df.na.fill(0)\n",
    "    \n",
    "    return daily_df\n",
    "    \n",
    "def vector_assembling(df):    \n",
    "    '''\n",
    "    Vector Assembling function\n",
    "    INPUT: df\n",
    "    OUTPUT:\n",
    "        columns_for_vector\n",
    "        df\n",
    "    '''\n",
    "\n",
    "    # create list of column names for features vector\n",
    "    columns_for_vector = df.columns\n",
    "    start_index = columns_for_vector.index('dayssinceJan11900')\n",
    "    del columns_for_vector[0:start_index+1]\n",
    "    to_make_label_index = columns_for_vector.index('sum(Churn)')\n",
    "    del columns_for_vector[to_make_label_index]\n",
    "\n",
    "    # create features vector\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=columns_for_vector,\n",
    "        outputCol=\"features\")\n",
    "\n",
    "    # transform daily_df\n",
    "    df = assembler.transform(df)\n",
    "    df = df.withColumnRenamed(\"sum(Churn)\",\"label\")\n",
    "    \n",
    "    return columns_for_vector, df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJwf6lmabCpw"
   },
   "source": [
    "# Modeling\n",
    "We will split the full dataset into train and test sets. We will test out several machine learning methods. We will evaluate the accuracy of the various models, tuning parameters as necessary. Finally, we will determine the winning model based on test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "6902a5cb97b44b77bbdfdcce7445a5c9",
      ""
     ]
    },
    "id": "8tGEWOUPbCpx",
    "outputId": "44f1ae33-0525-428b-bd32-b30ac61297c6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63720ead143940b6ae5cea079e89da67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def select_for_model(df):\n",
    "    # only take needed columns to model\n",
    "    ml_df = df.select('label','features')\n",
    "    \n",
    "    return ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "6945fbac8ed04a928d536a4dfd606b40",
      ""
     ]
    },
    "id": "srDmZObfbCpz",
    "outputId": "04cba4ba-06e3-4bab-d026-63fea85ce6b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c6c74c8dfb406b8e704ec9ac16fd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def oversampling(df):\n",
    "    # Implement Oversampling method\n",
    "\n",
    "    # calculate ratio\n",
    "    major_df = df.filter(df.label == 0)\n",
    "    minor_df = df.filter(df.label == 1)\n",
    "    ratio = int(major_df.count()/minor_df.count())\n",
    "    print(\"ratio: {}\".format(ratio))\n",
    "    a = range(ratio)\n",
    "\n",
    "    # duplicate the minority rows\n",
    "    oversampled_df = minor_df.withColumn(\"dummy\", F.explode(F.array([F.lit(x) for x in a]))).drop('dummy')\n",
    "\n",
    "    # combine both oversampled minority rows and previous majority rows \n",
    "    combined_df = major_df.unionAll(oversampled_df)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "8ee0c8e76e11455f91a4cb83bcacf6ce",
      ""
     ]
    },
    "id": "fqBvan_XbCp1",
    "outputId": "10987c22-2882-4ad6-a5ee-42be99909dfa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee0c8e76e11455f91a4cb83bcacf6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 60"
     ]
    }
   ],
   "source": [
    "# prep mini df\n",
    "\n",
    "# apply feature engineering\n",
    "prepped_df_mini = feature_engineering(df_mini)\n",
    "\n",
    "# apply vector assembling\n",
    "columns_for_vector, prepped_df_mini = vector_assembling(prepped_df_mini)\n",
    "\n",
    "# select columns for model\n",
    "prepped_df_mini = select_for_model(prepped_df_mini)\n",
    "\n",
    "# apply oversampling\n",
    "prepped_df_mini = oversampling(prepped_df_mini)\n",
    "\n",
    "# split dataframe into train and test datasets\n",
    "train_mini, test_mini = prepped_df_mini.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d97c7c510be3493d99dc93b9ecd2459e",
      ""
     ]
    },
    "id": "hxukBbR5bCp3",
    "outputId": "b0f2d909-6298-494f-f60c-21284fac08fe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ef0af131f54dbcad33e9f8855b8192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 57"
     ]
    }
   ],
   "source": [
    "# prep full df\n",
    "\n",
    "# apply feature engineering\n",
    "prepped_df = feature_engineering(df)\n",
    "\n",
    "# apply vector assembling\n",
    "columns_for_vector, prepped_df = vector_assembling(prepped_df)\n",
    "\n",
    "# select columns for model\n",
    "prepped_df = select_for_model(prepped_df)\n",
    "\n",
    "# apply oversampling\n",
    "prepped_df = oversampling(prepped_df)\n",
    "\n",
    "# split dataframe into train and test datasets\n",
    "train, test = prepped_df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "6588ef301db949e3b3c007dbf10bc0c7",
      ""
     ]
    },
    "id": "QhAL1d1CbCp5",
    "outputId": "f7afcd6e-3654-42be-bff7-f467a1816b60"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6588ef301db949e3b3c007dbf10bc0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 4893\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All correct predections count:  87022\n",
      "Total count:  172261\n",
      "Accuracy %:  50.517528633875344\n",
      "Recall %:  0.0"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "# create transformers\n",
    "scaler = StandardScaler(inputCol='features',outputCol='scaled_features')\n",
    "normalizer = Normalizer(inputCol='scaled_features',outputCol='norm_scaled_features')\n",
    "\n",
    "# set regression model\n",
    "lr =  LogisticRegression(labelCol=\"label\", featuresCol=\"norm_scaled_features\",maxIter=10, regParam=0.0, elasticNetParam=0)\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline(stages=[scaler, normalizer, lr])\n",
    "\n",
    "# run CV on train data\n",
    "lr_pipe = pipeline.fit(train)\n",
    "\n",
    "# create prediction column on test data\n",
    "results = lr_pipe.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdPCMWhqbCp8"
   },
   "outputs": [],
   "source": [
    "# evaluate results\n",
    "correct_count = results.filter(results.label == results.prediction).count()\n",
    "total_count = results.count()\n",
    "\n",
    "correct_1_count = results.filter((results.label == 1) & (results.prediction == 1)).count()\n",
    "total_1_test = results.filter((results.label == 1)).count()\n",
    "total_1_predict = results.filter((results.prediction == 1)).count()\n",
    "\n",
    "\n",
    "print(\"All correct predections count: \",correct_count)\n",
    "print(\"Total count: \",total_count)\n",
    "print(\"Accuracy %: \",(correct_count / total_count)*100)\n",
    "print(\"Recall %: \",(correct_1_count / total_1_test)*100)\n",
    "print(\"Precision %: \",(correct_1_count / total_1_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "6912ec5e26394c788e6a2c6232565108",
      ""
     ]
    },
    "id": "GWisqCl-bCp-",
    "outputId": "ae560239-3851-4303-ccd5-e1f78afb1bec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6912ec5e26394c788e6a2c6232565108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 5097\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All correct predections count:  119908\n",
      "Total count:  172261\n",
      "Accuracy %:  69.60832689929816\n",
      "Recall %:  66.4070015720688"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "# create transformers\n",
    "scaler = StandardScaler(inputCol='features',outputCol='scaled_features')\n",
    "normalizer = Normalizer(inputCol='scaled_features',outputCol='norm_scaled_features')\n",
    "\n",
    "# set rf model\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"norm_scaled_features\")\n",
    "\n",
    "# instantiate pipeline\n",
    "pipeline = Pipeline(stages=[scaler, normalizer, rf])\n",
    "\n",
    "# train model\n",
    "model_rf = pipeline.fit(train)\n",
    "\n",
    "# create prediction column on test data\n",
    "results = model_rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYzp_O1NbCqA"
   },
   "outputs": [],
   "source": [
    "# evaluate results\n",
    "correct_count = results.filter(results.label == results.prediction).count()\n",
    "total_count = results.count()\n",
    "\n",
    "correct_1_count = results.filter((results.label == 1) & (results.prediction == 1)).count()\n",
    "total_1_test = results.filter((results.label == 1)).count()\n",
    "total_1_predict = results.filter((results.prediction == 1)).count()\n",
    "\n",
    "\n",
    "print(\"All correct predections count: \",correct_count)\n",
    "print(\"Total count: \",total_count)\n",
    "print(\"Accuracy %: \",(correct_count / total_count)*100)\n",
    "print(\"Recall %: \",(correct_1_count / total_1_test)*100)\n",
    "print(\"Precision %: \",(correct_1_count / total_1_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "5d497397098345569ff815cf18227531",
      ""
     ]
    },
    "id": "uzKUcdtXbCqC",
    "outputId": "ed9b4d38-64ff-40cb-c8e0-f26fc36ec954"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d497397098345569ff815cf18227531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            importance\n",
      "sum(Downgrade)                                0.162432\n",
      "variance_daily_to_7d_avg_sum(Downgrade)       0.117103\n",
      "variance_daily_to_30d_avg_sum(Downgrade)      0.096459\n",
      "sum(Add Friend)_30d_avg                       0.082330\n",
      "sum(Downgrade)_7d_avg                         0.055010\n",
      "...                                                ...\n",
      "sum(Error)                                    0.000000\n",
      "sum(Upgrade)                                  0.000000\n",
      "variance_daily_to_30d_avg_sum(Roll Advert)    0.000000\n",
      "variance_daily_to_30d_avg_sum(Login)          0.000000\n",
      "variance_daily_to_7d_avg_sum(Register)        0.000000\n",
      "\n",
      "[122 rows x 1 columns]"
     ]
    }
   ],
   "source": [
    "# extract feature information\n",
    "tree = model_rf.stages[-1]\n",
    "\n",
    "t = tree.featureImportances\n",
    "\n",
    "df_f = pd.DataFrame(t.toArray(),\n",
    "                   index=columns_for_vector,\n",
    "                   columns=['importance'])\n",
    "\n",
    "df_f.sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "96efe1f4a79f48068bc77f56472cf598",
      ""
     ]
    },
    "id": "6Oqf7CNUbCqF",
    "outputId": "7aaa3d4a-b91e-452c-ec2f-8bd8a63a8323"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96efe1f4a79f48068bc77f56472cf598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread cell_monitor-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/awseditorssparkmonitoringwidget-1.0-py3.7.egg/awseditorssparkmonitoringwidget/cellmonitor.py\", line 178, in cell_monitor\n",
      "    job_binned_stages[job_id][stage_id] = all_stages[stage_id]\n",
      "KeyError: 2495\n",
      "\n",
      "name 'total_1_test' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'total_1_test' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USE the smaller dataset to go through the crossvalidation, the large dataset was too large\n",
    "# Gradient Boosting Tree\n",
    "\n",
    "# create transformers\n",
    "scaler = StandardScaler(inputCol='features',outputCol='scaled_features')\n",
    "normalizer = Normalizer(inputCol='scaled_features',outputCol='norm_scaled_features')\n",
    "\n",
    "# set a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"norm_scaled_features\", maxIter=10)\n",
    "\n",
    "# create ParamGrid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth,[10,20]) \\\n",
    "    .build()\n",
    "\n",
    "# set model Evaluator to \"f1\"\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# use CrossValidator to loop through the Paramgrid and use the best model\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# instantiate pipeline\n",
    "pipelineCV = Pipeline(stages=[scaler, normalizer, crossval])\n",
    "\n",
    "# run CV on train data\n",
    "cv_gbt = pipelineCV.fit(train_mini)\n",
    "\n",
    "# create prediction column on test dataframe\n",
    "results = cv_gbt.transform(test_mini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "71f73a31a1504b969a8760ef0740ce7d",
      ""
     ]
    },
    "id": "0Ac5zh6pbCqI",
    "outputId": "770f525a-ded7-460d-ac36-bc0331200518"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f73a31a1504b969a8760ef0740ce7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All correct predections count:  1878\n",
      "Total count:  1891\n",
      "Accuracy %:  99.31253305129562\n",
      "Recall %:  100.0\n",
      "Precision %:  98.6815415821501"
     ]
    }
   ],
   "source": [
    "# evaluate results\n",
    "correct_count = results.filter(results.label == results.prediction).count()\n",
    "total_count = results.count()\n",
    "\n",
    "correct_1_count = results.filter((results.label == 1) & (results.prediction == 1)).count()\n",
    "total_1_test = results.filter((results.label == 1)).count()\n",
    "total_1_predict = results.filter((results.prediction == 1)).count()\n",
    "\n",
    "\n",
    "print(\"All correct predections count: \",correct_count)\n",
    "print(\"Total count: \",total_count)\n",
    "print(\"Accuracy %: \",(correct_count / total_count)*100)\n",
    "print(\"Recall %: \",(correct_1_count / total_1_test)*100)\n",
    "print(\"Precision %: \",(correct_1_count / total_1_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f154e32c7a454d399fdd73c70be09efa",
      ""
     ]
    },
    "id": "1fdo3KxVbCqK",
    "outputId": "5203c610-c973-47b8-8219-40f783885f92"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f154e32c7a454d399fdd73c70be09efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='GBTClassifier_d2dd7fa4733f', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False, Param(parent='GBTClassifier_d2dd7fa4733f', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10, Param(parent='GBTClassifier_d2dd7fa4733f', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'all', Param(parent='GBTClassifier_d2dd7fa4733f', name='featuresCol', doc='features column name'): 'norm_scaled_features', Param(parent='GBTClassifier_d2dd7fa4733f', name='labelCol', doc='label column name'): 'label', Param(parent='GBTClassifier_d2dd7fa4733f', name='lossType', doc='Loss function which GBT tries to minimize (case-insensitive). Supported options: logistic'): 'logistic', Param(parent='GBTClassifier_d2dd7fa4733f', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be at least 2 and at least number of categories for any categorical feature.'): 32, Param(parent='GBTClassifier_d2dd7fa4733f', name='maxDepth', doc='Maximum depth of the tree. (Nonnegative) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20, Param(parent='GBTClassifier_d2dd7fa4733f', name='maxIter', doc='maximum number of iterations (>= 0)'): 10, Param(parent='GBTClassifier_d2dd7fa4733f', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256, Param(parent='GBTClassifier_d2dd7fa4733f', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='GBTClassifier_d2dd7fa4733f', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Must be at least 1.'): 1, Param(parent='GBTClassifier_d2dd7fa4733f', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='GBTClassifier_d2dd7fa4733f', name='seed', doc='random seed'): 3504127614838123891, Param(parent='GBTClassifier_d2dd7fa4733f', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='GBTClassifier_d2dd7fa4733f', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}\n",
      "                                             importance\n",
      "sum(Roll Advert)                               0.071815\n",
      "sum(About)_30d_avg                             0.051425\n",
      "sum(Downgrade)                                 0.049568\n",
      "sum(Thumbs Down)_30d_avg                       0.046903\n",
      "sum(Settings)                                  0.044878\n",
      "sum(Error)_30d_avg                             0.033657\n",
      "variance_7d_avg_to_30d_avg_sum(Help)_7d_avg    0.032643\n",
      "variance_daily_to_30d_avg_sum(Upgrade)         0.032640\n",
      "sum(Home)                                      0.029405\n",
      "sum(Roll Advert)_30d_avg                       0.029063"
     ]
    }
   ],
   "source": [
    "# extract best model and feature information\n",
    "treeCV = cv_gbt.stages[-1].bestModel\n",
    "print(treeCV.extractParamMap())\n",
    "\n",
    "# extract feature information\n",
    "tree = cv_gbt.stages[-1]\n",
    "\n",
    "t = treeCV.featureImportances\n",
    "\n",
    "df_cv = pd.DataFrame(t.toArray(),\n",
    "                   index=columns_for_vector,\n",
    "                   columns=['importance'])\n",
    "\n",
    "df_cv.sort_values('importance',ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNim1TTDbCqN"
   },
   "source": [
    "### Note: Running Gradient Boosting Tree with parameter input from CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "7c0a513509bc4d9f8a9baa800dede387",
      "0b77ee95f15e409a889aa7183038960b"
     ]
    },
    "id": "c3Q9_hFWbCqO",
    "outputId": "920e611f-1489-40d9-e439-1e9d7a150994"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1d2c1e6e8444ae830f8bdc8fd90696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosting Tree\n",
    "\n",
    "# create transformers\n",
    "scaler = StandardScaler(inputCol='features',outputCol='scaled_features')\n",
    "normalizer = Normalizer(inputCol='scaled_features',outputCol='norm_scaled_features')\n",
    "\n",
    "# set a GBT model: MaxDepth=10, due to performance issues, should be 20 based on crossvalidation above\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"norm_scaled_features\" \\\n",
    "                    , maxIter=10 \\\n",
    "                    , maxDepth=10)\n",
    "\n",
    "# instantiate pipeline\n",
    "pipeline = Pipeline(stages=[scaler, normalizer, gbt])\n",
    "\n",
    "# run CV on train data\n",
    "pipe_gbt = pipeline.fit(train)\n",
    "\n",
    "# create prediction column on test dataframe\n",
    "results = pipe_gbt.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UXpACmn_bKYr"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f38e4789b75414a8a1ee38bdbc6e513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All correct predections count:  151035\n",
      "Total count:  172261\n",
      "Accuracy %:  87.67800024381607\n",
      "Recall %:  94.64323423825056\n",
      "Precision %:  82.88332716886532"
     ]
    }
   ],
   "source": [
    "# evaluate results\n",
    "correct_count = results.filter(results.label == results.prediction).count()\n",
    "total_count = results.count()\n",
    "\n",
    "correct_1_count = results.filter((results.label == 1) & (results.prediction == 1)).count()\n",
    "total_1_predict = results.filter((results.prediction == 1)).count()\n",
    "total_1_test  = results.filter((results.label == 1)).count()\n",
    "\n",
    "print(\"All correct predections count: \",correct_count)\n",
    "print(\"Total count: \",total_count)\n",
    "print(\"Accuracy %: \",(correct_count / total_count)*100)\n",
    "print(\"Recall %: \",(correct_1_count / total_1_test)*100)\n",
    "print(\"Precision %: \",(correct_1_count / total_1_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "16cc37ccf8344026965d75f2e213a127"
     ]
    },
    "id": "dRE3Fv9RbCqP",
    "outputId": "8d7d4b7d-9623-4e61-f1e0-eb415467be50"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cb9597236a4ae4b3d3d8f72c260b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          importance\n",
      "sum(Downgrade)              0.037025\n",
      "sum(NextSong)               0.035929\n",
      "sum(Add Friend)             0.034679\n",
      "sum(Add Friend)_30d_avg     0.032163\n",
      "sum(Thumbs Up)              0.029579\n",
      "sum(Settings)               0.026360\n",
      "sum(Thumbs Down)_30d_avg    0.025391\n",
      "sum(Logout)                 0.022366\n",
      "sum(Home)                   0.019005\n",
      "sum(Thumbs Down)            0.018565"
     ]
    }
   ],
   "source": [
    "# extract feature information\n",
    "tree = pipe_gbt.stages[-1]\n",
    "\n",
    "t = tree.featureImportances\n",
    "\n",
    "df_gbt = pd.DataFrame(t.toArray(),\n",
    "                   index=columns_for_vector,\n",
    "                   columns=['importance'])\n",
    "\n",
    "df_gbt.sort_values('importance',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Als6838abCqS"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "In this notebook, I gave you some practical tools to predict churn:\n",
    "- We created a large set of calculated engagement metrics in our Feature Engineering segment\n",
    "- We gave you the secret to working with imbalanced data: Oversampling\n",
    "- We saw that the GradientBoostingTree Classifier works great on this dataset with x% accuracy\n",
    "\n",
    "If you are running this business, I would suggest looking at your Ads per user (or per session).\n",
    "\n",
    "\n",
    "## Reflection\n",
    "Particularly interesting to me was finding the oversampling method to work so effectively and giving me such accurate predictions.\n",
    "\n",
    "## Improvement\n",
    "The way I'm dealing with Vectors can probably be more elegant. I'm struggling to pull information in and out of these structures. Additionally I could have used PCA to reduce my feauter dimensionality, which would have improved overall speed of execution of the models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpSZ7LBWbCqS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sparkify.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
